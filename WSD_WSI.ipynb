{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "WSD_WSI.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "megn5EKEZKU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Cython numpy\n",
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvGeJiRHakcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWeHp-eavoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "21f1fcfe-4d0d-43cd-be54-72fc7fd84d4a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb_PNou3X7SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import adagram\n",
        "from lxml import html\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from string import punctuation\n",
        "import json, os\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "morph = MorphAnalyzer()\n",
        "punct = punctuation+'«»—…“”*№–'\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split() if word and word not in stops]\n",
        "    words = [word for word in words if word]\n",
        "\n",
        "    return words\n",
        "\n",
        "def normalize(text):\n",
        "    \n",
        "    words = tokenize(text)\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word]\n",
        "\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3_fRfuPbqFl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1cecc404-bf22-4f02-f978-49c39a300c0b"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-05dfb906-9ede-4b11-964f-9e0a27a5724a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-05dfb906-9ede-4b11-964f-9e0a27a5724a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving paraphrases.xml to paraphrases.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Wjk631X7TF",
        "colab_type": "text"
      },
      "source": [
        "## Задание № 1. Протестировать адаграм в определении перефразирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxm7a9SvX7TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "corpus_xml = html.fromstring(open('paraphrases.xml', 'rb').read())\n",
        "texts_1 = []\n",
        "texts_2 = []\n",
        "classes = []\n",
        "\n",
        "for p in corpus_xml.xpath('//paraphrase'):\n",
        "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
        "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
        "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
        "    \n",
        "data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IUgqCDxX7TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text_1_norm'] = data['text_1'].apply(normalize)\n",
        "data['text_2_norm'] = data['text_2'].apply(normalize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPkLg9LLvjek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_t_data = []\n",
        "for t in data['text_1_norm']:\n",
        "  f_t_data += t\n",
        "for t in data['text_2_norm']:\n",
        "  f_t_data += t\n",
        "f = open('first_task_corpus.txt', 'w')\n",
        "f.write(' '.join(f_t_data))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW1suCnGyITj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e21c47b0-9d6c-4e5d-ad92-6e7ae8cb7e5c"
      },
      "source": [
        "!adagram-train first_task_corpus.txt f_t_out.pkl"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] 2020-03-05 17:40:45,063 Building dictionary...\n",
            "[INFO] 2020-03-05 17:40:45,286 Done! 1839 words.\n",
            "[INFO] 2020-03-05 17:40:51,478 92.70% -6.7697 0.0018 1.7/2.0 10.44 kwords/sec\n",
            "[INFO] 2020-03-05 17:40:51,965 100.00% -6.7668 0.0000 1.7/2.0 10.35 kwords/sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJy5Zrkfydis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_t_vm = adagram.VectorModel.load(\"f_t_out.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti67KPk3X7TK",
        "colab_type": "text"
      },
      "source": [
        "Векторизуйте пары текстов с помощью Адаграма, обучите любую модель и оцените качество (кросс-валидацией). \n",
        "\n",
        "За основу возьмите код из предыдущего семинара/домашки, только в функции get_embedding вам нужно выбирать вектор нужного значения (импользуйте model.disambiguate и model.sense_vector). Отдельные векторы усредните как и в предыдущем семинаре."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHXOKnRNX7TL",
        "colab_type": "text"
      },
      "source": [
        "Для вытаскивания пар (целевое слово, контекстые слова) вам нужно будет написать специальную функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oruaejOPX7TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# проверяте на списке из чисел, чтобы было удобно дебажить\n",
        "words = [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "def get_words_in_context(words, window=3):\n",
        "    words_in_context = []\n",
        "    for i in range(len(words)):\n",
        "      l = len(words)\n",
        "      s_1, e_1, s_2, e_2 = 0,0,l,l\n",
        "      if i > window:\n",
        "        s_1 = i - window\n",
        "      if i > 0:\n",
        "        e_1 = i\n",
        "      if i < l - 1:\n",
        "        s_2 = i + 1\n",
        "      if l - i >= window:\n",
        "        e_2 = s_2 + window\n",
        "      word = words[i]\n",
        "      context = words[s_1:e_1] + words[s_2:e_2]\n",
        "      words_in_context.append([word, context])\n",
        "\n",
        "    return words_in_context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "x1ILgoj3X7TO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0b5168ac-ca9c-42e0-ed86-5d684e9cce97"
      },
      "source": [
        "# работать должно вот так\n",
        "get_words_in_context(words)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, [1, 2, 3]],\n",
              " [1, [0, 2, 3, 4]],\n",
              " [2, [0, 1, 3, 4, 5]],\n",
              " [3, [0, 1, 2, 4, 5, 6]],\n",
              " [4, [1, 2, 3, 5, 6, 7]],\n",
              " [5, [2, 3, 4, 6, 7, 8]],\n",
              " [6, [3, 4, 5, 7, 8, 9]],\n",
              " [7, [4, 5, 6, 8, 9]],\n",
              " [8, [5, 6, 7, 9]],\n",
              " [9, [6, 7, 8]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGMOcBGWX7TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding_adagram(text, model, window, dim):\n",
        "    \n",
        "    word2context = get_words_in_context(text, window)\n",
        "    \n",
        "    \n",
        "    vectors = np.zeros((len(word2context), dim))\n",
        "    \n",
        "    for i, (word, context) in enumerate(word2context):\n",
        "        \n",
        "        try:\n",
        "            a_m = model.disambiguate(word, context).argmax()\n",
        "            v = vm.sense_vector(word, a_m)\n",
        "            print(v)\n",
        "            vectors[i] = v\n",
        "        \n",
        "        except (KeyError, ValueError):\n",
        "            continue\n",
        "    \n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03et18Pu7NBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "n_fold = 10\n",
        "stratified_folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "grid = {\n",
        "    'max_features': [50,100,150],\n",
        "    'random_state': [42]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FStGeIKb7tNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 100\n",
        "X_text_1_ada = np.zeros((len(data['text_1_norm']), dim))\n",
        "X_text_2_ada = np.zeros((len(data['text_2_norm']), dim))\n",
        "\n",
        "for i in range(len(data['text_1_norm'])):\n",
        "    X_text_1_ada[i] = get_embedding_adagram(data['text_1_norm'][i], f_t_vm, 3, dim)\n",
        "    \n",
        "for i in range(len(data['text_2_norm'])):\n",
        "    X_text_2_ada[i] = get_embedding_adagram(data['text_2_norm'][i], f_t_vm, 3, dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n60JAOTG9gXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_ada = np.concatenate([X_text_1_ada, X_text_2_ada], axis=1)\n",
        "y = classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6FtoUdK94_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "def grid_search_best(model, grid, folds, grid_train_data, grid_train_classes):\n",
        "  grid_search = GridSearchCV(model, param_grid=grid, cv=folds, scoring='f1_macro')\n",
        "  grid_search.fit(grid_train_data, grid_train_classes) \n",
        "  return grid_search.best_score_, grid_search.best_params_, grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onlMRzaH-ofo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score, params, estimator = grid_search_best(model, grid, stratified_folds, X_text_ada, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byshKFXq_zUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cf6bd45-0791-46c6-a31c-6d476cc0f0a3"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4025943215461577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f69bfbb9-8473-4538-95ad-a870ebac0994",
        "id": "oTDHOoVpG9yz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# запустите если не установлен ворднет\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ojMuE6X7UU",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2. Реализовать алгоритм Леска и проверить его на реальном датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmEgu2TVX7UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "def lesk( word, sentence ):\n",
        "    bestsense = 0\n",
        "    maxoverlap = 0\n",
        "\n",
        "    synsets = wn.synsets(word)\n",
        "    \n",
        "    for i, syns in enumerate(synsets):\n",
        "      overlap = 0\n",
        "      for s in sentence:\n",
        "        if s in syns.definition():\n",
        "          overlap += 1\n",
        "      if overlap > maxoverlap:\n",
        "        bestsense = i\n",
        "        maxoverlap = overlap\n",
        "        \n",
        "        \n",
        "    return bestsense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm6if2rdX7UX",
        "colab_type": "text"
      },
      "source": [
        "Работать функция должна как-то так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhTTcTw2X7UY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce834f65-110b-4d1d-f730-d54954244b42"
      },
      "source": [
        "# на вход подается элемент результата работы уже написанной вами функции get_words_in_context\n",
        "lesk('day', 'some point or period in time'.split()) # для примера контекст совпадает с одним из определений\n",
        "# а на выходе индекс подходящего синсета"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIg3l0A0X7Ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "155f04d3-2913-441a-f4ec-54cf28c3dccd"
      },
      "source": [
        "# с помощью этого индекса достаем нужный синсет\n",
        "wn.synsets('day')[1].definition()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some point or period in time'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HWXdruhX7Ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_wsd = []\n",
        "corpus = open('corpus_wsd_50k.txt').read().split('\\n\\n')\n",
        "for sent in corpus:\n",
        "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7wGt7GOX7Uq",
        "colab_type": "text"
      },
      "source": [
        "**Вам нужно для каждого многозначного слова (т.е. у него есть тэг в первом поле) с помощью алгоритма Леска предсказать нужный синсет и сравнить с правильным. Посчитайте процент правильных предсказаний (accuracy).**\n",
        "\n",
        "Если считается слишком долго, возьмите поменьше предложений (например, только тысячу)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PidxYESDo_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_context(words, i, window=5):\n",
        "  l = len(words)\n",
        "  s_1, e_1, s_2, e_2 = 0,0,l,l\n",
        "  if i > window:\n",
        "    s_1 = i - window\n",
        "  if i > 0:\n",
        "    e_1 = i\n",
        "  if i < l - 1:\n",
        "    s_2 = i + 1\n",
        "  if l - i >= window:\n",
        "    e_2 = s_2 + window\n",
        "  context = words[s_1:e_1] + words[s_2:e_2]\n",
        "  return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlWlEnOVDDZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "windows = [3,5,7,9]\n",
        "best_acc = 0\n",
        "best_window = 0\n",
        "for window in windows:\n",
        "  true = 0\n",
        "  total = 0\n",
        "  for sent in corpus_wsd[:1000]:\n",
        "    words = []\n",
        "    for w in sent:\n",
        "      words.append(w[2])\n",
        "    for i in range(len(sent)):\n",
        "      w = sent[i]\n",
        "      if w[0] == \"\":\n",
        "        continue\n",
        "      total += 1\n",
        "      ctx = get_context(words, i, window)\n",
        "      sense = lesk(w[1], ctx)\n",
        "      if wn.synsets(w[1])[sense] == wn.lemma_from_key(w[0]).synset():\n",
        "        true += 1\n",
        "    acc = true/total\n",
        "    if acc > best_acc:\n",
        "      best_window = window\n",
        "      best_acc = acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQaynRIkHWwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58751616-ea57-410b-9152-152156373093"
      },
      "source": [
        "print(best_acc, best_window)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5081967213114754 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwCVDxNZX7Uq",
        "colab_type": "text"
      },
      "source": [
        "### Дополнительный балл"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc10sD9xX7Uq",
        "colab_type": "text"
      },
      "source": [
        "Если хотите заработать дополнительный балл, попробуйте улучшить алгоритм Леска любым способом (например, использовать расстояние редактирования вместо пересечения или даже вставить машинное обучение)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlcZWoXz7qIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard_metric (a,b,c):\n",
        "  if a+b-c == 0:\n",
        "    return 0.0001\n",
        "  return c/(a+b-c)\n",
        "\n",
        "def serensen_metric(a,b,c):\n",
        "  if a+b == 0:\n",
        "    return 0.0001\n",
        "  return 2*c/(a+b)\n",
        "\n",
        "def simpson_metric(a,b,c):\n",
        "  if min(a,b) == 0:\n",
        "    return 0.0001\n",
        "  return c/min(a,b)\n",
        "\n",
        "def braun_metric(a,b,c):\n",
        "  if max(a,b) == 0:\n",
        "    return 0.0001\n",
        "  return c/max(a,b)\n",
        "\n",
        "def compare_words(w1, w2, w_threshold, metric):\n",
        "  a = len(w1)\n",
        "  b = len(w2)\n",
        "  c = 0\n",
        "  \n",
        "  for i in range(len(w1)-1):\n",
        "    first = w1[i:i+1]\n",
        "    for j in range(len(w2)-1):\n",
        "      if w2[j:j+1] == first:\n",
        "        c += 1\n",
        "        break\n",
        "\n",
        "  return  metric(a,b,c) > w_threshold\n",
        "\n",
        "def compare_sents(s1, s2, w_threshold, metric):\n",
        "  if type(s1) != list:\n",
        "    s1 = s1.split()\n",
        "  if type(s2) != list:\n",
        "    s2 = s2.split()\n",
        "\n",
        "  s1 = [w for w in s1 if len(w) > 2]\n",
        "  s2 = [w for w in s2 if len(w) > 2]\n",
        "\n",
        "  c = 0\n",
        "  a = len(s1)\n",
        "  b = len(s2)\n",
        "  for first in s1:\n",
        "    for second in s2:\n",
        "      if compare_words(first, second, w_threshold, metric):\n",
        "        c += 1\n",
        "        break\n",
        "  return metric(a,b,c)\n",
        "\n",
        "def new_lesk( word, sentence, w_threshold, metric):\n",
        "    bestsense = 0\n",
        "    best_metric = 0\n",
        "\n",
        "    synsets = wn.synsets(word)\n",
        "    \n",
        "    for i, syns in enumerate(synsets):\n",
        "      overlap = 0\n",
        "      m_score = compare_sents(sentence, syns.definition(), w_threshold, metric)\n",
        "      if m_score > best_metric:\n",
        "        bestsense = i\n",
        "        maxoverlap = overlap\n",
        "        \n",
        "        \n",
        "    return bestsense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LS9DSJLNK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prev_best_score = best_acc\n",
        "prev_best_window = best_window\n",
        "best_metric = None\n",
        "best_threshold = 0\n",
        "best_score = 0\n",
        "best_w = 0\n",
        "\n",
        "metrics = [jaccard_metric, serensen_metric, simpson_metric, braun_metric]\n",
        "w_thresholds = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "for metric in metrics:\n",
        "  for w_t in w_thresholds:\n",
        "    windows = [3,5,7,9]\n",
        "    best_acc = 0\n",
        "    best_window = 0\n",
        "    for window in windows:\n",
        "      true = 0\n",
        "      total = 0\n",
        "      for sent in corpus_wsd[:1000]:\n",
        "        words = []\n",
        "        for w in sent:\n",
        "          words.append(w[2])\n",
        "        for i in range(len(sent)):\n",
        "          w = sent[i]\n",
        "          if w[0] == \"\":\n",
        "            continue\n",
        "          total += 1\n",
        "          ctx = get_context(words, i, window)\n",
        "          sense = new_lesk(w[1], ctx, w_t, metric)\n",
        "          if wn.synsets(w[1])[sense] == wn.lemma_from_key(w[0]).synset():\n",
        "            true += 1\n",
        "        acc = true/total\n",
        "        if acc > best_acc:\n",
        "          best_window = window\n",
        "          best_acc = acc\n",
        "    if best_acc > prev_best_score:\n",
        "      best_metric = metric\n",
        "      best_threshold = w_t\n",
        "      best_score = best_acc\n",
        "      best_w = best_window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl2nKQ97MgKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4528fb03-7cf1-4799-f57b-b9e16cb8cf88"
      },
      "source": [
        "print(best_metric, best_threshold, best_score, best_w)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function braun_metric at 0x7fa0fa607d90> 1 0.6239316239316239 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij8nSLFUWtSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a2912a9-dd79-45c1-9fec-6a85b1a4ef16"
      },
      "source": [
        "prev_best_score = best_acc\n",
        "print(prev_best_score, best_score)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5081967213114754 0.6239316239316239\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}