{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7pIf6AIQTh1",
        "colab_type": "text"
      },
      "source": [
        "# 1 задание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqjDLyUaE9ed",
        "colab_type": "code",
        "outputId": "b2386b53-791c-407b-cee9-c055406d3d5a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31d6756e-706c-4bd0-8184-eed88cfdfab2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-31d6756e-706c-4bd0-8184-eed88cfdfab2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving corpus_hum.txt to corpus_hum.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6WUPs4mFBrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "csv_path = \"data_paraphraser_norm.csv\"\n",
        "texts_1, texts_2 = [], []\n",
        "classes = []\n",
        "with open(csv_path, \"r\") as f:\n",
        "  reader = csv.DictReader(f)\n",
        "  for line in reader:\n",
        "    texts_1.append(line[\"text_1_norm\"])\n",
        "    texts_2.append(line[\"text_2_norm\"])\n",
        "    classes.append(line[\"label\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbG497yPFtWy",
        "colab_type": "code",
        "outputId": "839c469d-2a48-4871-db99-c2edb1484d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbe2uknNHR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def clear_sent(sent):\n",
        "  return ' '.join([re.sub('_.*', '', w) for w in sent.split()])\n",
        "texts_1_no_tags = [clear_sent(s) for s in texts_1]\n",
        "texts_2_no_tags = [clear_sent(s) for s in texts_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuRHZhARPBFu",
        "colab_type": "code",
        "outputId": "ac8e8a3b-c3ac-4653-c63a-f8992c0664e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(texts_1[0])\n",
        "print(texts_1_no_tags[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "полицейский_NOUN разрешать_VERB стрелять_VERB на_ADP поражение_NOUN по_ADP гражданин_NOUN с_ADP травматика_NOUN\n",
            "полицейский разрешать стрелять на поражение по гражданин с травматика\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c66AZYXdb_VS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "828dfb4d-b95f-4d48-edc5-08dbd0c56229"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.2MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ltKKpzi92C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f50d8b3c-63ef-47f5-8ee3-62e77a791a1f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "morph = MorphAnalyzer()\n",
        "punct = punctuation+'«»—…“”*№–'\n",
        "stops = set(stopwords.words('russian'))\n",
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e5EhH0TJXXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d91c5d4d-cff7-4679-c81a-458c27a533d1"
      },
      "source": [
        "data = open('corpus_hum.txt').read().splitlines()\n",
        "\n",
        "data_norm = [normalize(text) for text in data]\n",
        "data_norm = [text for text in data_norm if text]\n",
        "data_norm[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['абай василий васо иван 1900–2001 русский лингвист родиться 2 15 декабрь 1900 с.коби тифлисский губерния ныне грузия 1925 окончить факультет общественный наука ленинградский университет 1928 аспирантура 1928–1930 сотрудник кавказский историко-археологический институт ан ссср 1930 полвека работать яфетический институт затем институт язык мышление институт языкознание ан ссср ленинград 1950 москва доктор филологический наука 1962 профессор 1969 лауреат государственный премия ссср 1981 почётный член азиатский королевский общество великобритания ирландия 1966 член-корреспондент финно-угорский общество хельсинки 1973 умереть абай москва 18 март 2001',\n",
              " 'также тема',\n",
              " 'лингвистика языкознание языковедение',\n",
              " 'ученик н.я.марра ранний работа находиться влияние идея который впоследствии отойти видный специалист история иранский язык свой родной осетинский язык автор фундаментальный историко-этимологический словарь осетинский язык 5-ти том 1958–1990 заниматься также мифология фольклор иранский народ осетинский литература',\n",
              " 'теоретик лингвистика выступить 1934 концепция разграничивать аспект язык техника стандартный обозначение язык явление действительность формальный средство такой обозначение идеология отражение язык иной мировоззрение слово другой единица язык первоначально идеологичный затем происходить технизация выветривание первоначальный идеологический представление позволять единица сохраняться изменение идеология 1965 выступить резка критика структурализм дегуманизация лингвистический наука изучение язык отрыв говорящий человек мышление']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-iuep0dJ8CO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "d2d4132d-9caf-4492-8c06-d4e9036c7018"
      },
      "source": [
        "import gensim\n",
        "w2v = gensim.models.Word2Vec([text.split() for text in data_norm], size=50, sg=1)\n",
        "w2v.most_similar('язык')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('древнееврейский', 0.8031230568885803),\n",
              " ('иврит', 0.8012332320213318),\n",
              " ('латынь', 0.7776556015014648),\n",
              " ('церковно-славянский', 0.7645127177238464),\n",
              " ('украинск', 0.7639732360839844),\n",
              " ('фарси', 0.7615458965301514),\n",
              " ('идиш', 0.7530549168586731),\n",
              " ('фольклор', 0.7513177990913391),\n",
              " ('по-арабски', 0.7499111294746399),\n",
              " ('осетинский', 0.743545413017273)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GATL13MImu0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c9861581-a28a-4842-c144-6fe5180a491c"
      },
      "source": [
        "!wget https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz\n",
        "!gunzip news_upos_cbow_300_2_2017.bin.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 08:11:01--  https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140310878 (134M) [application/x-gzip]\n",
            "Saving to: ‘news_upos_cbow_300_2_2017.bin.gz’\n",
            "\n",
            "news_upos_cbow_300_ 100%[===================>] 133.81M  28.5MB/s    in 5.4s    \n",
            "\n",
            "2020-02-19 08:11:07 (24.6 MB/s) - ‘news_upos_cbow_300_2_2017.bin.gz’ saved [140310878/140310878]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKBH5d4pmy6m",
        "colab_type": "code",
        "outputId": "571c492d-5ba7-47a4-ff11-e584b0b995c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "w2v_external = gensim.models.KeyedVectors.load_word2vec_format(datapath(\"/content/news_upos_cbow_300_2_2017.bin\"), binary=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssSewargKiIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter,defaultdict\n",
        "def get_embedding(text, model, dim):\n",
        "    text = text.split()\n",
        "    \n",
        "    # чтобы не доставать одно слово несколько раз\n",
        "    # сделаем счетчик, а потом векторы домножим на частоту\n",
        "    words = Counter(text)\n",
        "    total = len(text)\n",
        "    vectors = np.zeros((len(words), dim))\n",
        "    \n",
        "    for i,word in enumerate(words):\n",
        "        try:\n",
        "            v = model[word]\n",
        "            vectors[i] = v*(words[word]/total) # просто умножаем вектор на частоту\n",
        "        except (KeyError, ValueError):\n",
        "            continue\n",
        "    \n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvUJdX9-Tm8q",
        "colab_type": "code",
        "outputId": "206fd6e1-5996-44aa-f1eb-8e6d2c73a4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "dim = 50\n",
        "X_text_1_w2v = np.zeros((len(texts_1_no_tags), dim))\n",
        "X_text_2_w2v = np.zeros((len(texts_2_no_tags), dim))\n",
        "\n",
        "for i in range(len(texts_1_no_tags)):\n",
        "    X_text_1_w2v[i] = get_embedding(texts_1_no_tags[i], w2v, dim)\n",
        "    \n",
        "for i in range(len(texts_2_no_tags)):\n",
        "    X_text_2_w2v[i] = get_embedding(texts_2_no_tags[i], w2v, dim)\n",
        "\n",
        "X_text_1_w2v_external = np.zeros((len(texts_1), dim))\n",
        "X_text_2_w2v_external = np.zeros((len(texts_2), dim))\n",
        "\n",
        "for i in range(len(texts_1)):\n",
        "    X_text_1_w2v_external[i] = get_embedding(texts_1[i], w2v_external, dim)\n",
        "    \n",
        "for i in range(len(texts_2)):\n",
        "    X_text_2_w2v_external[i] = get_embedding(texts_2[i], w2v_external, dim)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKuvO9-Pt34E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_w2v = np.concatenate([X_text_1_w2v, X_text_2_w2v], axis=1)\n",
        "X_text_w2v_external = np.concatenate([X_text_1_w2v_external, X_text_2_w2v_external], axis=1)\n",
        "y = classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoA07IjFKxAc",
        "colab_type": "code",
        "outputId": "58d0fbce-9e19-4957-ed75-2c6573391ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "n_fold = 10\n",
        "stratified_folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "f1 = 0\n",
        "for train_index, valid_index in stratified_folds.split(X_text_w2v, y):\n",
        "    train_texts = [X_text_w2v[i] for i in train_index]\n",
        "    train_results = [y[i] for i in train_index]\n",
        "    test_texts = [X_text_w2v[i] for i in valid_index]\n",
        "    test_results = [y[i] for i in valid_index]\n",
        "    model = linear_model.LogisticRegression(class_weight='balanced')\n",
        "    model.fit(train_texts, train_results)\n",
        "    preds = model.predict(test_texts)\n",
        "    f1_fold= f1_score(test_results, preds, average='weighted')\n",
        "    f1 += f1_fold\n",
        "f1_external = 0\n",
        "stratified_folds_external = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "for train_index, valid_index in stratified_folds_external.split(X_text_w2v_external, y):\n",
        "    train_texts = [X_text_w2v_external[i] for i in train_index]\n",
        "    train_results = [y[i] for i in train_index]\n",
        "    test_texts = [X_text_w2v_external[i] for i in valid_index]\n",
        "    test_results = [y[i] for i in valid_index]\n",
        "    model = linear_model.LogisticRegression(class_weight='balanced')\n",
        "    model.fit(train_texts, train_results)\n",
        "    preds = model.predict(test_texts)\n",
        "    f1_fold = f1_score(test_results, preds, average='micro')\n",
        "    f1_external += f1_fold\n",
        "  \n",
        "print(\"my w2v: \", f1/n_fold)\n",
        "print(\"rusvectores w2v: \", f1_external/n_fold)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my w2v:  0.4186536288337878\n",
            "rusvectores w2v:  0.3572717554970633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZakC3-15VgY",
        "colab_type": "text"
      },
      "source": [
        "Обученная модель показала себя лучше, чем взятая с rusvectores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO6-x_LQQYZI",
        "colab_type": "text"
      },
      "source": [
        "# 2 задание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPiD4kQrEaGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft = gensim.models.FastText([text.split() for text in data_norm], size=50, \n",
        "                                   min_n=4, max_n=8) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X2nyVMY7Efw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "05507ba0-934d-476a-84f4-e411526abe42"
      },
      "source": [
        "ft.most_similar('язык')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('н.м.язык', 0.9947590231895447),\n",
              " ('праязык', 0.9452675580978394),\n",
              " ('подъязык', 0.916778564453125),\n",
              " ('язык-предок', 0.8909441232681274),\n",
              " ('языкова', 0.8596363067626953),\n",
              " ('метаязык', 0.8408960700035095),\n",
              " ('язык-цель', 0.8406948447227478),\n",
              " ('протоязык', 0.8103739619255066),\n",
              " ('языковед', 0.7974911332130432),\n",
              " ('диалектолог', 0.755706787109375)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8_aoZlyGcnB",
        "colab_type": "code",
        "outputId": "f486f4fb-3256-43aa-b59b-37b3a65434c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_text_1_ft = np.zeros((len(texts_1_no_tags), dim))\n",
        "X_text_2_ft = np.zeros((len(texts_2_no_tags), dim))\n",
        "for i in range(len(texts_1_no_tags)):\n",
        "    X_text_1_ft[i] = get_embedding(texts_1_no_tags[i], ft, dim)\n",
        "    \n",
        "for i in range(len(texts_2_no_tags)):\n",
        "    X_text_2_ft[i] = get_embedding(texts_2_no_tags[i], ft, dim)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwP7u9vb7iDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "cv = CountVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
        "X = cv.fit_transform(texts_1 + texts_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvRpR8eG7c6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "svd = TruncatedSVD(200)\n",
        "svd = svd.fit(X)\n",
        "X_text_1_svd = svd.transform(cv.transform(texts_1))\n",
        "X_text_2_svd = svd.transform(cv.transform(texts_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNGoyYHTGTra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmf = NMF(50)\n",
        "nmf = nmf.fit(X)\n",
        "X_text_1_nmf = nmf.transform(cv.transform(texts_1))\n",
        "X_text_2_nmf = nmf.transform(cv.transform(texts_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEPML4gcMzLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def micro_f1_for_multiple_models(models):\n",
        "  distances = []\n",
        "  for i in range(len(y)):\n",
        "    d = []\n",
        "    for model in models:\n",
        "      d.append(cosine_similarity(model[0][i].reshape(1, -1), model[1][i].reshape(1, -1)))\n",
        "    distances.append(d)\n",
        "  reshaped_distances = []\n",
        "  for d in distances:\n",
        "    r_d = []\n",
        "    for item in d:\n",
        "      r_d.append(item[0][0])\n",
        "    reshaped_distances.append(r_d)\n",
        "  n_fold = 10\n",
        "  f1_multi = 0\n",
        "  stratified_folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "  for train_index, valid_index in stratified_folds.split(reshaped_distances, y):\n",
        "    train_texts = [reshaped_distances[i] for i in train_index]\n",
        "    train_results = [y[i] for i in train_index]\n",
        "    test_texts = [reshaped_distances[i] for i in valid_index]\n",
        "    test_results = [y[i] for i in valid_index]\n",
        "    model = linear_model.LogisticRegression(class_weight='balanced')\n",
        "    model.fit(train_texts, train_results)\n",
        "    preds = model.predict(test_texts)\n",
        "    f1_fold= f1_score(test_results, preds, average='micro')\n",
        "    f1_multi += f1_fold\n",
        "  return f1_multi/n_fold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUmsAufyNiqL",
        "colab_type": "code",
        "outputId": "f99066d2-568c-4586-bcdb-27453198f372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "models = [[X_text_1_svd,X_text_2_svd],\n",
        "          [X_text_1_nmf,X_text_2_nmf],\n",
        "          [X_text_1_ft,X_text_2_ft],\n",
        "          [X_text_1_w2v,X_text_2_w2v],\n",
        "          [X_text_1_w2v_external,X_text_2_w2v_external]]\n",
        "print(micro_f1_for_multiple_models(models))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4813833557468688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMmDpaWAMZcY",
        "colab_type": "text"
      },
      "source": [
        "Результат стал лучше, попробуем поменять параметры у методов векторизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9dt8sHVLRJv",
        "colab_type": "code",
        "outputId": "69907acd-be21-4d1c-870c-0c5d1612772a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "min_dfs = [1,3,5]\n",
        "max_dfs = [0.2,0.4,0.6]\n",
        "max_features = [500,1000,1500]\n",
        "for min_df in min_dfs:\n",
        "  for max_df in max_dfs:\n",
        "    for max_feature in max_features:\n",
        "      new_cv = CountVectorizer(min_df=min_df, max_df=max_df, max_features=max_feature)\n",
        "      new_X = new_cv.fit_transform(texts_1 + texts_2)\n",
        "      new_svd = TruncatedSVD(200)\n",
        "      new_svd = new_svd.fit(new_X)\n",
        "      new_nmf = NMF(50)\n",
        "      new_nmf = new_nmf.fit(new_X)\n",
        "      new_X_text_1_svd = new_svd.transform(new_cv.transform(texts_1))\n",
        "      new_X_text_2_svd = new_svd.transform(new_cv.transform(texts_2))\n",
        "      new_X_text_1_nmf = new_nmf.transform(new_cv.transform(texts_1))\n",
        "      new_X_text_2_nmf = new_nmf.transform(new_cv.transform(texts_2))\n",
        "      new_models = [\n",
        "          [new_X_text_1_svd,new_X_text_2_svd],\n",
        "          [new_X_text_1_nmf,new_X_text_2_nmf],\n",
        "          [X_text_1_ft,X_text_2_ft],\n",
        "          [X_text_1_w2v,X_text_2_w2v],\n",
        "          [X_text_1_w2v_external,X_text_2_w2v_external]]\n",
        "      print(\"min_df: \", min_df, \" max_df: \", max_df, \" max_features: \", max_feature, \" micro_f1: \", micro_f1_for_multiple_models(new_models))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min_df:  1  max_df:  0.2  max_features:  500  micro_f1:  0.4765408826718467\n",
            "min_df:  1  max_df:  0.2  max_features:  1000  micro_f1:  0.47681731627605817\n",
            "min_df:  1  max_df:  0.2  max_features:  1500  micro_f1:  0.4751562242579587\n",
            "min_df:  1  max_df:  0.4  max_features:  500  micro_f1:  0.4802768550553059\n",
            "min_df:  1  max_df:  0.4  max_features:  1000  micro_f1:  0.47986134258993196\n",
            "min_df:  1  max_df:  0.4  max_features:  1500  micro_f1:  0.47654030796580893\n",
            "min_df:  1  max_df:  0.6  max_features:  500  micro_f1:  0.4844275736294219\n",
            "min_df:  1  max_df:  0.6  max_features:  1000  micro_f1:  0.4823534595387793\n",
            "min_df:  1  max_df:  0.6  max_features:  1500  micro_f1:  0.4834601517990215\n",
            "min_df:  3  max_df:  0.2  max_features:  500  micro_f1:  0.47571139029053305\n",
            "min_df:  3  max_df:  0.2  max_features:  1000  micro_f1:  0.4758491281709406\n",
            "min_df:  3  max_df:  0.2  max_features:  1500  micro_f1:  0.47224993582449254\n",
            "min_df:  3  max_df:  0.4  max_features:  500  micro_f1:  0.48096650230073984\n",
            "min_df:  3  max_df:  0.4  max_features:  1000  micro_f1:  0.48027628034926806\n",
            "min_df:  3  max_df:  0.4  max_features:  1500  micro_f1:  0.4788927713474558\n",
            "min_df:  3  max_df:  0.6  max_features:  500  micro_f1:  0.48332164764389685\n",
            "min_df:  3  max_df:  0.6  max_features:  1000  micro_f1:  0.48055328865951735\n",
            "min_df:  3  max_df:  0.6  max_features:  1500  micro_f1:  0.4831833350574515\n",
            "min_df:  5  max_df:  0.2  max_features:  500  micro_f1:  0.4783402872763915\n",
            "min_df:  5  max_df:  0.2  max_features:  1000  micro_f1:  0.47322023118508216\n",
            "min_df:  5  max_df:  0.2  max_features:  1500  micro_f1:  0.47211526304295354\n",
            "min_df:  5  max_df:  0.4  max_features:  500  micro_f1:  0.4780632789661422\n",
            "min_df:  5  max_df:  0.4  max_features:  1000  micro_f1:  0.4788927713474559\n",
            "min_df:  5  max_df:  0.4  max_features:  1500  micro_f1:  0.47695486258778635\n",
            "min_df:  5  max_df:  0.6  max_features:  500  micro_f1:  0.4822151469523339\n",
            "min_df:  5  max_df:  0.6  max_features:  1000  micro_f1:  0.48332126450653823\n",
            "min_df:  5  max_df:  0.6  max_features:  1500  micro_f1:  0.48179963448695995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz39PB8cRHTi",
        "colab_type": "text"
      },
      "source": [
        "Наилучшие результаты при CountVectorizer(min_df=1, max_df=0.6, max_features=500) - 0.4844275736294219"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EPKcPgPTpBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "51a35262-4789-4226-ca44-c2d43ce845e1"
      },
      "source": [
        "best_cv = CountVectorizer(min_df=1, max_df=0.6, max_features=500)\n",
        "best_X = best_cv.fit_transform(texts_1 + texts_2)\n",
        "best_svd = TruncatedSVD(200)\n",
        "best_svd = best_svd.fit(best_X)\n",
        "best_nmf = NMF(50)\n",
        "best_nmf = best_nmf.fit(best_X)\n",
        "best_X_text_1_svd = best_svd.transform(best_cv.transform(texts_1))\n",
        "best_X_text_2_svd = best_svd.transform(best_cv.transform(texts_2))\n",
        "best_X_text_1_nmf = best_nmf.transform(best_cv.transform(texts_1))\n",
        "best_X_text_2_nmf = best_nmf.transform(best_cv.transform(texts_2))\n",
        "\n",
        "sgs = [0, 1]\n",
        "hss = [0, 1]\n",
        "sizes = [25,50,75,100]\n",
        "for sg in sgs:\n",
        "  for hs in hss:\n",
        "    for size in sizes:\n",
        "      new_w2v = gensim.models.Word2Vec([text.split() for text in data_norm], size=size, sg=sg, hs=hs)\n",
        "      new_X_text_1_w2v = np.zeros((len(texts_1_no_tags), dim))\n",
        "      new_X_text_2_w2v = np.zeros((len(texts_2_no_tags), dim))\n",
        "\n",
        "      for i in range(len(texts_1_no_tags)):\n",
        "        new_X_text_1_w2v[i] = get_embedding(texts_1_no_tags[i], new_w2v, dim)\n",
        "    \n",
        "      for i in range(len(texts_2_no_tags)):\n",
        "        new_X_text_2_w2v[i] = get_embedding(texts_2_no_tags[i], new_w2v, dim)\n",
        "\n",
        "\n",
        "      new_models = [\n",
        "          [best_X_text_1_svd,best_X_text_2_svd],\n",
        "          [best_X_text_1_nmf,best_X_text_2_nmf],\n",
        "          [X_text_1_ft,X_text_2_ft],\n",
        "          [new_X_text_1_w2v,new_X_text_2_w2v],\n",
        "          [X_text_1_w2v_external,X_text_2_w2v_external]]\n",
        "      print(\"sg: \", sg, \" hs: \", hs, \" size: \", size, \" micro_f1: \", micro_f1_for_multiple_models(new_models))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  0  size:  25  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  0  size:  50  micro_f1:  0.4692106987276009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  0  size:  75  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  0  size:  100  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  1  size:  25  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  1  size:  50  micro_f1:  0.48332030666314185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  1  size:  75  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  0  hs:  1  size:  100  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  0  size:  25  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  0  size:  50  micro_f1:  0.4824927299686211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  0  size:  75  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  0  size:  100  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  1  size:  25  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  1  size:  50  micro_f1:  0.49065777021720053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  1  size:  75  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sg:  1  hs:  1  size:  100  micro_f1:  0.4699039857779413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzJoPSS1h-Hz",
        "colab_type": "text"
      },
      "source": [
        "Наилучшие результаты при Word2Vec(size=50, sg=1, hs=1) - 0.49065777021720053 (на самом деле возможен и результат лучше т.к. в прошлый раз при size=50, sg=1, hs=0 был результат 0.4844275736294219, а сейчас он 0.4824927299686211)\n",
        "Параметры fasttext перебирать не стал т.к. долго делается"
      ]
    }
  ]
}